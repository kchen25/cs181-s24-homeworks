{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS 181 HW4 Problem 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only code you have to write are places marked with a TODO comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading datasets for K-Means and HAC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "from scipy.spatial import distance\n",
    "\n",
    "small_dataset = np.load(\"data/small_dataset.npy\")\n",
    "small_labels = np.load(\"data/small_dataset_labels.npy\").astype(int)\n",
    "large_dataset = np.load(\"data/large_dataset.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    # K is the K in KMeans\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "\n",
    "    # X is a (N x 28 x 28) array where 28x28 is the dimensions of each of the N images.\n",
    "    def fit(self, X):\n",
    "        # TODO: implement this function\n",
    "        pass\n",
    "\n",
    "    # This should return the arrays for K images. Each image should represent the mean of each of the fitted clusters.\n",
    "    def get_mean_images(self):\n",
    "        # TODO: change this!\n",
    "        return small_dataset[:self.K]\n",
    "    \n",
    "    # TODO: change this for part 1's plot\n",
    "    def plot_verify_objective(self):\n",
    "        pass\n",
    "    \n",
    "    # TODO: change this for part 5\n",
    "    def get_cluster_sizes(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: This takes seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KMeansClassifier = KMeans(K=10)\n",
    "KMeansClassifier.fit(large_dataset)\n",
    "KMeansClassifier.plot_verify_objective()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting code for parts 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mean_image_plot(data, standardized = False):\n",
    "    niters = 3\n",
    "    K = 10\n",
    "    allmeans = np.zeros((K, niters, 784))\n",
    "    for i in range(niters):\n",
    "        KMeansClassifier = KMeans(K=K)\n",
    "        KMeansClassifier.fit(data)\n",
    "        allmeans[:,i] = KMeansClassifier.get_mean_images()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.suptitle('Class mean images across random restarts' + (' (standardized data)' if standardized else ''), fontsize=16)\n",
    "    for k in range(K):\n",
    "        for i in range(niters):\n",
    "            ax = fig.add_subplot(K, niters, 1+niters*k+i)\n",
    "            plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            plt.setp(ax.get_yticklabels(), visible=False)\n",
    "            ax.tick_params(axis='both', which='both', length=0)\n",
    "            if k == 0: plt.title('Iter '+str(i))\n",
    "            if i == 0: ax.set_ylabel('Class '+str(k), rotation=90)\n",
    "            plt.imshow(allmeans[k,i].reshape(28,28), cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: This takes ~3 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_mean_image_plot(large_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: This takes ~3 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataset_std = None # TODO\n",
    "make_mean_image_plot(large_dataset_std, standardized = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAC: Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAC(object):\n",
    "    def __init__(self, linkage):\n",
    "        self.linkage = linkage\n",
    "    \n",
    "    def fit(self, X):\n",
    "        # TODO: implement the function\n",
    "        pass\n",
    "\n",
    "    # Returns the mean image when using n_clusters clusters\n",
    "    def get_mean_images(self, n_clusters):\n",
    "        # TODO: Change this!\n",
    "        return small_dataset[:n_clusters]\n",
    "    \n",
    "    # Return assignments when there were K clusters\n",
    "    def get_k_clusters(self, K):\n",
    "        # TODO: implement the function\n",
    "        pass\n",
    "\n",
    "    # Get cluster sizes to compare min and max linkage\n",
    "    def get_cluster_sizes(self, K):\n",
    "        # TODO: implement the function\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: This takes ~6 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKAGES = [ 'max', 'min', 'centroid' ]\n",
    "n_clusters = 10\n",
    "cluster_sizes = []\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle(\"HAC mean images with max, min, and centroid linkagess\")\n",
    "for l_idx, l in enumerate(LINKAGES):\n",
    "    # Fit HAC\n",
    "    hac = HAC(l)\n",
    "    hac.fit(small_dataset)\n",
    "    mean_images = hac.get_mean_images(n_clusters)\n",
    "    cluster_sizes.append(hac.get_cluster_sizes(n_clusters)) # used in Part 8, append here to avoid re-fitting\n",
    "    # Make plot\n",
    "    for m_idx in range(mean_images.shape[0]):\n",
    "        m = mean_images[m_idx]\n",
    "        ax = fig.add_subplot(n_clusters, len(LINKAGES), l_idx + m_idx*len(LINKAGES) + 1)\n",
    "        plt.setp(ax.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax.get_yticklabels(), visible=False)\n",
    "        ax.tick_params(axis='both', which='both', length=0)\n",
    "        if m_idx == 0: plt.title(l)\n",
    "        if l_idx == 0: ax.set_ylabel('Class '+str(m_idx), rotation=90)\n",
    "        plt.imshow(m.reshape(28,28), cmap='Greys_r')\n",
    "    print(\"Done:\", l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Create the graph for comparing cluster sizes in K-means\n",
    "def plot_cluster_sizes(n_clusters, cluster_sizes):\n",
    "    fig, (ax) = plt.subplots(1, 1)\n",
    "    fig.suptitle(\"K-means Cluster Sizes\")\n",
    "    ax.set_ylabel('number of images in cluster')\n",
    "    cluster_idxs = [i for i in range(n_clusters)]\n",
    "\n",
    "    def plot_sizes_per_linkage(ax, sizes, k):\n",
    "        ax.bar(cluster_idxs, sizes)\n",
    "        ax.set_title(f'K = {k}')\n",
    "        ax.set_xlabel('cluster index')\n",
    "        ax.set_ylim(0, 1000)\n",
    "\n",
    "    plot_sizes_per_linkage(ax, cluster_sizes, str(n_clusters))\n",
    "    plt.show()\n",
    "\n",
    "plot_cluster_sizes(KMeansClassifier.K, KMeansClassifier.get_cluster_sizes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5: Create the graph for comparing cluster sizes in HAC\n",
    "def plot_cluster_sizes(n_clusters, cluster_sizes):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    fig.suptitle(\"HAC Cluster Sizes\")\n",
    "    ax1.set_ylabel('number of images in cluster')\n",
    "    cluster_idxs = [i for i in range(n_clusters)]\n",
    "\n",
    "    def plot_sizes_per_linkage(ax, sizes, linkage):\n",
    "        ax.bar(cluster_idxs, sizes)\n",
    "        ax.set_title(f'{linkage} Linkage')\n",
    "        ax.set_xlabel('cluster index')\n",
    "        ax.set_ylim(0, 300)\n",
    "\n",
    "    plot_sizes_per_linkage(ax1, cluster_sizes[0], 'Max')\n",
    "    plot_sizes_per_linkage(ax2, cluster_sizes[1], 'Min')\n",
    "    plot_sizes_per_linkage(ax3, cluster_sizes[2], 'Centroid')\n",
    "    plt.show()\n",
    "plot_cluster_sizes(n_clusters, cluster_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement code to produce confusion matrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c365ea26a318e0b540d1978e97e3d03cfe51dff8cd04dae5f3d7b47d79d2453"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
