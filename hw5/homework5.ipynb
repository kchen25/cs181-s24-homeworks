{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CS 181 HW5**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize data and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a specific example of when we have $K = 3$ component Gamma distributions. Let's initialize the initial parameter values for $\\theta$ and $\\beta_k$ as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\theta_k &=  1/K, \\\\\n",
    "  \\beta_k & = k/K.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note that we usually initialize $\\theta$ and $\\beta_k$ randomly. However, by fixing the initial $\\theta$ and $\\beta_k$, EM becomes deterministic which makes debugging (and grading) easier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributions as ds\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "x = torch.load('data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment to use numpy (optional)\n",
    "# import numpy as np\n",
    "# from scipy.stats import gamma\n",
    "# x = x.numpy()\n",
    "# theta = theta.numpy()\n",
    "# betas = betas.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement the E-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(theta, betas):\n",
    "    q = 'not implemented'\n",
    "    return q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement the M-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(q):\n",
    "    theta_hat = 'not implemented'\n",
    "    beta_hats = 'not implemented'\n",
    "    return theta_hat, beta_hats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_px(x, theta, betas):\n",
    "    p = 'not implemented'\n",
    "    return p\n",
    "\n",
    "def log_likelihood(theta, betas):\n",
    "    return log_px(x, theta, betas).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_em(theta, betas, iterations=1000):\n",
    "    theta = 'not implemented'\n",
    "    betas = 'not implemented'\n",
    "    return theta, betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "mnist_trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)  # download MNIST\n",
    "N = 6000 \n",
    "\n",
    "x = mnist_trainset.data[:N]  # select N datapoints\n",
    "x = x.flatten(1)             # flatten the images\n",
    "x = x.float()                # convert pixels from uint8 to float\n",
    "# x = x.numpy()              # uncomment to use numpy (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** implement PCA\n",
    "\n",
    "*Hint: see `.linalg.svd()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(x, n_comps=500):\n",
    "    top_eigvals = 'not implemented'\n",
    "    top_pcomps = 'not implemented'\n",
    "    return top_eigvals, top_pcomps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** calculate cumulative fraction of variance\n",
    "\n",
    "*Hint: see `.cumsum()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cfvs(eigvals):\n",
    "    cum_frac_vars = 'not implemented'\n",
    "    return cum_frac_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Todo:** calculate mean squared L2 norm reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_errs(x, pcomps):\n",
    "    err_mean = 'not implemented'\n",
    "    err_pcomp = 'not implemented'\n",
    "    return err_mean, err_pcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and print errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pic(pic, ax, title=''):\n",
    "    x = pic.reshape(28, 28)\n",
    "    ax.imshow(x, cmap='binary')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def make_plots(eigvals, cfvs, x_mean, pcomps):\n",
    "    # plot eigenvals and cfvs\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "    ax1.plot(eigvals, color='tomato')\n",
    "    ax1.set_title('Eigenvalues')\n",
    "    ax2.plot(cfvs, color='tomato')\n",
    "    ax2.set_title('CFVs')\n",
    "    fig.savefig('p3_cfvs.pdf')\n",
    "\n",
    "    # plot mean\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "    plot_pic(x_mean, ax, title='Mean')\n",
    "    fig.savefig('p3_mean.pdf')\n",
    "\n",
    "    # plot top 10 pcomps\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "        plot_pic(pcomps[i], axes.flat[i], title=f'PC index {i}')\n",
    "    fig.savefig('p3_pcomps.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do PCA\n",
    "eigvals, pcomps = pca(x)\n",
    "\n",
    "# calculate CFVs\n",
    "fcvs = calc_cfvs(eigvals)\n",
    "\n",
    "# print errors\n",
    "err_mean, err_pcomp = calc_errs(x, pcomps)\n",
    "print(f'Reconstruction error (using mean): {err_mean:3e}')\n",
    "print(f'Reconstruction error (using mean and top 10 pcomps): {err_pcomp:3e}')\n",
    "\n",
    "# make plots\n",
    "make_plots(eigvals, fcvs, x.mean(0), pcomps)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c365ea26a318e0b540d1978e97e3d03cfe51dff8cd04dae5f3d7b47d79d2453"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
